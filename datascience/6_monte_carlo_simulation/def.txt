a method for estimating a unknown value 
    using inferential statistics¹ 

components²:
    population: universe of possible examples
    sample: a proper subset of the population. 
        proper: > 0 < population
        KEY: HAS TO BE RANDOM.
        KEY: a random sample tends to exhibits the same properties of population. 
            
predicting/guessing outcome:
    Given:
        2 sample outcome A => no/very low confidence
        100 sample outcome A => high confidence of next outcome to be A
        52 sample outcome A, 48 outcome B => 52/100 confidence, not high confidence

    Why different confidence?
        Varibility => variance
            high variance => less confidence. need larger sample for same confidence.
            low variance => high confidence. need smaller sample for same confidence.

        Example:
            Roulette
                100 spins, same bet = high variance of expected return.
                    SN: the high variance is what makes it Gambling attractive to people.
                1000000 spins, same bet = low variance variance of expected return.

    Statistics thereoms that explain and predict these observations:
        Law of Large Numbers:
            def: Given repeated indepedent tests
                    with same probability p for some outcome A
                    the chance 
                        that the fraction of times
                            outcome A occurs
                        differs from p coverges to 0(zero)
                    as the number of tests approaches infinity
            ENGLISH: Given inifinte spins, expected return is 0?

            Misconceptions: if deviations from norm occur, 
                                the norm is more likely to even out events.

                - Gambler's Fallacy
                    summary: subsequent will be BELOW the Mean, to even out the extreme events.

        Regression to the Mean:
            def: following an extreme event
                    the next random event is likely to be less extreme
            example: 
                child height:
                    assumption: people height is random(NOT accounting for genetics)
                    given 
                        2 parents 
                            taller than average
                        child islikely to be shorter than average

                roullete:

Sampling:
    perfect accuracy NOT guaranteed.
    differentiate:
        - what happens to be true
                    from
        - what we know is true(through rigor/good reason)

    Core Computational Statistics Question:
        How many samples do we need to look at
            to have justifiable confidence in the answer?
            
            - Depends on: 
                variability of possibilities in the data
                    
                    Quantity variability
                        X = list of possible possibilities
                        μ = Mean of X
                    
                        variance(X) = ΣₓₑX (x - μ)² 
                                     ---------------
                                           |X|

                                    English: sum of 
                                                how far from the mean
                                                    each possibilty(xₑX) is
                                                    i.e. How different from the mean is each value?
                                             squared
                                             divided by number of elements
                                    
                                    Why sqaure?
                                        Do not care if distance negative/positive
                                        Distincly highlights the outliers

                                    Why divide by |X|?
                                        We don't want to say
                                            X has high variance
                                                because it has large population.
                                        i.e. normalises by number of members

                        Standard deviation = σ(X) = sqrt(variance(X))
                                                  = sqrt(
                                                           1  
                                                          --- Σ(x - μ)² 
                                                          |X|ₓₑX      
                                                        )

                                i.e squareroot of variance(X)
                            English: By what value are the members(looked as a whole) different from the Mean.
                                     i.e. By how much do they "deviate" from the Mean

                            MUST always be thought in context of Mean
                            Example: 
                                standard deviation = 100 => meanignless
                                standard deviation = 100 and Mean = 100 => standard deviation is large
                                standard deviation = 100 and Mean = 1000000000 => standard deviation is small

Problem: Often attempt to describe/estimate an unknown value by a single value(e.g Mean)
    Better approach: Confidence Intervals

- Confidence Levels and Intervals
    def: RANGE OF VALUES within which the unknown value is likely to exist
         and the CONFIDENCE that it will exist in the range.
    
        e.g. For 20 trials
                For 100 spins of Roulette
                        Expect your return will be between 1% and -1%
                        95% of the time

        Properties:
            The smaller the range = BETTER constraint range
                    ∴ good reason to believe
                        computed Mean is closer to the True Mean.

        NB: As Trials approach infinity, the simulated Mean approaches True Mean.

    Calculation/Computation Methods:
        - Empirical rule
        - 

        - Empirical rule
            - Assumptions required for rule to work:
                - The Mean estimation error is zero(0)
                    i.e. Equally likely to guess High or Low
                - The Distibution of the errors in the estimate is NORMAL(i.e. gaussian distribution)
            def: 
                Given 
                    data
                    Mean of data
                    Standard deviation of data
                Then
                    ~66% of data will be within 1 standard deviations of Mean
                    ~95% of data will be within 1.96 standard deviations Mean
                    ~99.7% of data will be within 3 standard deviations of Mean

Distibutions
    types:
        - Probability distribution
        
        - Probability distribution
            def: relative frequency with which
                    some random variable 
                        takes on different values.

            types:
                - Discrete
                - Continous

                - Discrete
                    def: The different values are drawn from FINITE SET of values.
                        e.g. for coin flip, only Heads or Tails possible.
                             distribution = probability of heads + probability of tails
                                NB: Must equal 1
                        i.e. distribution = sum of probability of each value

                - Continous
                    def: The different values are drawn from a SET of REALS(Real Numbers)
                            between two numbers.
                        e.g. 1 to 2
                             Infinite numbers beween 1 and 2.
                    ∴ can't enumerate and sum all probabilities of different values in an infinite set.
                            ACTUALLY probability of each value
                                in an infinite set is close to zero/zero(when set is truly inifinte)

                    ∴ SOLUTION: Probability Density Function(PDF)
                        def: probablity of a random variable 
                                lying between two numbers.

references: 
    1,2 John Guttag, Lecture 6: Monte Carlo Simulation, MIT 6.0002, https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/lecture-videos/lecture-6-monte-carlo-simulation/
